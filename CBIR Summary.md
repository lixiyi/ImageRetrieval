# CBIR 综述

## 最常引述的方法分类
* 常用检索词：
  * locality sensitive hashing，ITQ，product quantization，inverted multi-index，笛卡尔k-means，hamming embedding
* 重要技术：特征提取（表示）、索引构建（存储）、近邻搜索（查找）
* 表示方法（局部特征、全局特征）
  * 特征按提取方式分为`传统特征`和`深度特征`
  * 在图像检索领域，基于CNN提取的深度特征同样也表现出远优于传统特征的效果，所以`只研究深度特征`
  * 手工特征（传统特征）：
    * SIFT（全局）、GIST（全局）、HOG、HARR
  * 深度学习特征：卷积层的输出为局部特征，FC层输出是全局特征
    * RMAC、GEM
* 存储方法（稀疏化）
  * 特征按照存储方式又分为`浮点特征`和`二进制特征`
    * 浮点特征：
      * 优点：表征图像信息，进行距离计算时能够更加细粒度地衡量图像间的差异
      * 缺点：距离计算复杂度较高，此外浮点向量在进行存储时占用空间也更大
    * 二进制特征：
      * 优点：存储更加高效，且向量间差异通常采用hamming距离衡量，计算复杂度较低
      * 缺点：距离衡量粒度较粗，如对于128维度的二级制特征，图像间差异只存在128个数值范围内
  * 浮点特征
    * 特征编码：
      * BOF(Bag Of Feature, Bag Of Visual Words, BOW)、Fisher Vector、VLAD 
      * 局部特征聚合成全局特征、量化成视觉词汇短语
      * 聚合方法的特征维度比原始特征维度更高，因此若后续对聚合后的特征进行PCA操作，会增加计算复杂度，同时还可能导致数据过拟合
    * 深度特征：
      * Sum-pooling (SPoC) 、RMAC、GEM
      * 在分类数据集上训练得到的深度特征应用于不同数据集的检索任务时仍然起作用
      * 在检索数据集上finetune分类模型，能够大幅提高检索效果
      * PCA降维应用于深度特征能够在几乎不降低检索准确率的同时有效压缩特征长度
  * 二进制特征：Embedding成二进制特征
    * spectral hashing、sigmoid 0.5 hard thresholding
    * 将二进制特征用作减小搜索空间的一种方式，采用`多级查找方式`：首先对查询图像与目标数据库中的图像的二进制特征进行汉明距离计算，选取top N距离对应的图像，然后再进行浮点向量间的距离计算，优化查找准确率
    * `汉明距离`：两个等长字符串之间的汉明距离是两个字符串对应位置的不同字符的个数。换句话说，它就是将一个字符串变换成另外一个字符串所需要替换的字符个数
* 查找方法
  * 倒排索引：将特征向量聚类成codewords，相当于把浮点向量离散化到一维或者多维的格子里，每个格子对应一个codewords，查找时离散化到格子里再更精细地查找
    * K-Means、ANN、K-D Tree、PQ
  * Hash：哈希成二进制比特串之后用multi-index的数据结构来做汉明空间内的最近邻搜索，或者直接穷举地查找
    * LSH

## 各方法详解

* `特征编码：用来将局部特征聚合生成更强可辨识性的图像特征。这些方法通常会生成比原始局部特征更高维度的向量，尽管如此，Embedding后的向量维度也远远低于BoF的维度`

* BOF

  * 核心思想：
    * 提取出局部向量（视觉词汇）后利用聚类的方法训练一个视觉字典，随后每幅图片用视觉词汇在视觉字典中各中心向量出现的次数来表示该图片
  * 缺点：
    * 数据量很大的情况下，由于vocabulary大小的限制，BOF的特征表达会越来越粗略（视觉字典不够完整）
    * BOF只用离特征点`最近的一个聚类中心`代替该特征点，损失较多信息。
    * 搜索效率降低，图像表示占用的内存巨大（Query时得为每个局部向量确定视觉词汇，即找到聚类中心，词表很大的情况下很慢）

* Fisher Vector

  * 核心思想：
    * 对于两幅不同的输入图像，其特征点的分布可能是相同的，但是其`变化方向（梯度）相同的概率非常小`，因此可以用分布的梯度来更加准确地表示输入图像
    * 利用高斯混合模型(GMM)，通过计算高斯混合模型中的均值、协方差等参数来表示每张图像
    * 质心数k通常取16～256即可得到较好的效果
  * 优点：
    * 准确度高
  * 缺点：
    * 计算量大（查询时依旧大）
    * 用所有`聚类中心 ( Gussian ) 的线性组合`来表示特征点，但是用GMM建模的过程中也有损失信息

* VLAD

  * 核心思想：

    ![VLAD](./img/VLAD.png)

    * 一种简化的FV，其主要方法是通过聚类方法训练一个小的视觉字典
    * 对于每幅图像中的局部特征找到最近的聚类中心（视觉词汇），随后所有特征与聚类中心的差值做累加，得到一个 k x d 的 VLAD 矩阵，其中k是聚类中心个数，d是特征维数 (如sift是128维)
    * 随后将该矩阵扩展为一个(k*d)维的向量，并对其L2归一化，所得到的向量即为VLAD

  * 优点：

    * 可以理解为BOF和Fisher Vector的折中, VLAD保存了每个特征点到离它`最近`的聚类中心的距离，并且像Fisher Vector 考虑了特征点的`每一维`的值。
    * 相比BoF，准确率更高，便于降维（PCA），同时降维对于准确率的影响也较小

* Triangular embedding

* SPoC

  * 核心思想：
    * 最后一个卷积层CxHxW，每个Channel上Sum得到长度为C的向量
    * 核心信息在图像中央：Sum时乘上位置稀疏（Gussian得到）
    * PCA白化、去相关性或降维，L2归一化
  * 优点：
    * 累加求和生成的聚合特征SPoC的检索效果优于使用VLAD，Fisher Vector和Triangular embedding等方法得到的聚合特征的检索效果
    * 深度卷积特征与传统特征的分布特性不同，前者比后者具有更高的可辨识性，因此可以无需使用面向传统特征的聚合方法VLAD、Fisher Vector、Triangular embedding

* RMAC

  * 核心思想：
    * 最后一个卷积层上取Region，每个Region用RoiPooling后得到长度为Region数量的向量，Sum所有Region，L2，PCA，L2

## 重要问题

* 查找性能优化

## 重要的优点和特性

* 向量的稀疏性：便于构建倒排索引

## 应用场景

* 搜索引擎（Google、百度）的以图搜图功能
* 各电商网站（淘宝、Amazon、ebay）的相似商品搜索
* 社交平台（Pinterest）的相似内容推荐



# 工业界产品调研

* [`CBIR Engine List`](https://en.wikipedia.org/wiki/List_of_CBIR_engines) 

### [LIRE](http://www.lire-project.net/)

* Java Lib 基于颜色和纹理特征进行图像检索
* 用全局和局部的特征生成Lucene的索引

### [TinEye](https://tineye.com/)

* matchEngine: 利用像素，而`非图片内容`生成和比较图像的数字指纹
* 用于发现重复的图片，无法发现同一物体不同角度的图

### [Visenze](https://www.visenze.com/)
* 购物推荐：款式类似的服饰
* 深度学习图片识别

### [SnapFashion](https://www.snapfashion.com)
* 购物：相似的颜色和形状